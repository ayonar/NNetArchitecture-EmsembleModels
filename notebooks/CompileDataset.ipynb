{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compile Dataset into pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(mypath) :\n",
    "    data = []\n",
    "    for fname in os.listdir(mypath):\n",
    "        pathname = os.path.join(mypath, fname)\n",
    "        #img = Image.open(pathname)\n",
    "        #data.append(img)\n",
    "        with Image.open(pathname) as img:\n",
    "            img2 = np.array(img)\n",
    "            data.append(img2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.abspath('./data')\n",
    "dataset_dir\n",
    "mypaths=[os.path.dirname(dataset_dir + \"/PolygonImagesV7/3/image_0.png\"),\n",
    "         os.path.dirname(dataset_dir + \"/PolygonImagesV7/4/image_20000.png\"),\n",
    "         os.path.dirname(dataset_dir + \"/PolygonImagesV7/5/image_40000.png\")]\n",
    "dataset = []\n",
    "for mypath in mypaths:\n",
    "    tempdata = load_dataset(mypath)\n",
    "    data = np.array(tempdata)\n",
    "    np.random.shuffle(data)\n",
    "    dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset into train validatin and test sets.\n",
    "train_x = np.concatenate((dataset[0][:12000], dataset[1][:12000], dataset[2][:12000]), axis=0)\n",
    "val_x = np.concatenate((dataset[0][12000:16000], dataset[1][12000:16000], dataset[2][12000:16000]), axis=0)\n",
    "test_x = np.concatenate((dataset[0][16000:20000], dataset[1][16000:20000], dataset[2][16000:20000]), axis=0)\n",
    "\n",
    "train_y = np.concatenate(( np.zeros(int(len(train_x)/len(mypaths))) , np.ones(int(len(train_x)/len(mypaths))) , 2*np.ones(int(len(train_x)/len(mypaths))) ) , axis=0)\n",
    "val_y = np.concatenate(( np.zeros(int(len(val_x)/len(mypaths))) , np.ones(int(len(val_x)/len(mypaths))) , 2*np.ones(int(len(val_x)/len(mypaths))) ) , axis=0)\n",
    "test_y = np.concatenate(( np.zeros(int(len(test_x)/len(mypaths))) , np.ones(int(len(test_x)/len(mypaths))) , 2*np.ones(int(len(test_x)/len(mypaths))) ) , axis=0)\n",
    "\n",
    "# could use glob. think about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del (data, dataset, tempdata, mypath, mypaths, Image, glob, load_dataset, np, os, pickle, plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type       Data/Info\n",
      "-------------------------------\n",
      "dill       module     <module 'dill' from 'C:\\\\<...>ages\\\\dill\\\\__init__.py'>\n",
      "filename   str        PolygonImagesV7.pkl\n",
      "test_x     ndarray    12000x45x45: 24300000 elems, type `uint8`, 24300000 bytes (23.174285888671875 Mb)\n",
      "test_y     ndarray    12000: 12000 elems, type `float64`, 96000 bytes\n",
      "train_x    ndarray    36000x45x45: 72900000 elems, type `uint8`, 72900000 bytes (69.52285766601562 Mb)\n",
      "train_y    ndarray    36000: 36000 elems, type `float64`, 288000 bytes (281.25 kb)\n",
      "val_x      ndarray    12000x45x45: 24300000 elems, type `uint8`, 24300000 bytes (23.174285888671875 Mb)\n",
      "val_y      ndarray    12000: 12000 elems, type `float64`, 96000 bytes\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAADTVJREFUeJzt3X/oXfV9x/Hna9GYzlZsWpXMyHRF\nNstYU3BOcH+4WDeXlmrBga6MDAJ2MMHSsho32Cy0oNDW/rHhsNOZQVftbIsibl2ISimM+DN1sVkb\n69yaJpiVNlQHs0bf++OejG+z7ze5uffcX/k8H3C595zvud/7PpKXn3M+33PfJ1WFpPb83KwLkDQb\nhl9qlOGXGmX4pUYZfqlRhl9qlOGXGmX4pUaNFf4kVyX5TpIXkmztqyhJk5dRr/BLsgr4LnAlsA94\nEri+qr690ntW57Raw+kjfZ6k4/sf/puf1msZZttTxvicS4AXqupFgCT3AVcDK4Z/DafzG7lijI+U\ndCw7a8fQ245z2H8u8P0ly/u6dZIWwDgj/3KHFv/vHCLJDcANAGv4+TE+TlKfxhn59wHnLVleD+w/\neqOququqLq6qi0/ltDE+TlKfxgn/k8CFSS5Ishq4Dnion7IkTdrIh/1VdTjJjcDXgVXAPVX1fG+V\nSZqocc75qapHgEd6qkXSFHmFn9Qowy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81yvBL\njTL8UqMMv9Qowy81yvBLjRrr+/xJXgJeAd4ADlfVxX0UJWnyxgp/57eq6oc9/B5JU+Rhv9SoccNf\nwD8nebpr0S1pQYx72H9ZVe1PcjawPcm/VdU3lm5g335pPo018lfV/u75IPA1BrfwOnob+/ZLc2jk\n8Cc5PcnbjrwGfhvY3VdhkiZrnMP+c4CvJTnye/6+qv6pl6okTdw4N+14EXhPj7VImiL/1Cc1yvBL\njTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9SoPnr4nbS+vn9Xb7/rd35hQ2+/\nS+qDI7/UKMMvNeq44U9yT5KDSXYvWbc2yfYke7vnt0+2TEl9G+ac/17gL4G/W7JuK7Cjqm5LsrVb\nvrn/8k4efc4fDMt5Bh3LcUf+rhvvj45afTWwrXu9Dbim57okTdio5/znVNUBgO757P5KkjQNE/9T\nn337pfk06sj/cpJ1AN3zwZU2tG+/NJ9GHfkfAjYDt3XPD/ZWkXrjJKOOZZg/9X0J+Bfgl5PsS7KF\nQeivTLIXuLJblrRAjjvyV9X1K/zoip5rkTRFXuEnNcrwS43yW33HcPTk1Swm0BaNk4yLw5FfapTh\nlxpl+KVGGX6pUU74aeE5yTgaR36pUYZfapThlxpl+KVGOeEnjaDvScZZTCA68kuNMvxSowy/1KhR\nb9pxa5IfJNnVPTZNtkxJfRv1ph0Ad1TVZ3qvSDrJzcvVgaPetEPSghvnnP/GJM91pwUr3qsvyQ1J\nnkry1Ou8NsbHSerTqOG/E3gXsAE4AHx2pQ3t2y/Np5HCX1UvV9UbVfUm8AXgkn7LkjRpI13hl2Td\nkXv1AR8Cdh9re6lV8zK5t5zjhr+7acflwDuT7AP+Arg8yQaggJeAj0ywRkkTMOpNO+6eQC2Spsgr\n/KRG+a2+E7Dc+Zu9/HXEPJ/fL8eRX2qU4ZcaZfilRhl+qVFO+EkjWLTJveU48kuNMvxSowy/1CjD\nLzXKCT/pOE6Gyb3lOPJLjTL8UqMMv9SoYfr2n5fksSR7kjyf5KZu/dok25Ps7Z5XbOIpaf4MM+F3\nGPh4VT2T5G3A00m2A38I7Kiq25JsBbYCN0+uVGk6TtYJvqMN07f/QFU9071+BdgDnAtcDWzrNtsG\nXDOpIiX174TO+ZOcD7wX2Amcc6SJZ/d89grvsW+/NIeGDn+StwJfAT5aVT8Z9n327Zfm01DhT3Iq\ng+B/saq+2q1+Ocm67ufrgIOTKVHSJAzTujsMuvXuqarPLfnRQ8Bm4Lbu+cGJVChNUCuTe8sZZrb/\nMuAPgH9NcqRb5Z8yCP2Xk2wB/hP4vcmUKGkShunb/00gK/z4in7LkTQtXuEnNcrwS43yK71j8kYe\ni6Plyb3lOPJLjTL8UqMMv9Qoz/l1UvL8/vgc+aVGGX6pUYZfapThlxrlhJ8WnpN7o3Hklxpl+KVG\nGX6pUeP07b81yQ+S7OoemyZfrqS+jNO3H+COqvrM5MqTfpaTe/0ZppPPAeBIi+5Xkhzp2y9pgY3T\ntx/gxiTPJbnH23VJi2Wcvv13Au8CNjA4MvjsCu/zph3SHBq5b39VvVxVb1TVm8AXgEuWe6837ZDm\n08h9+5OsO3K7LuBDwO7JlKhWObk3WeP07b8+yQaggJeAj0ykQkkTMU7f/kf6L0fStHiFn9Qowy81\nyq/0am44wTddjvxSowy/1CjDLzXK8EuNcsJvArx5pxaBI7/UKMMvNcrwS43ynF8z4QU9s+fILzXK\n8EuNMvxSo4bp278myRNJvtX17f9kt/6CJDuT7E1yf5LVky9XUl+GmfB7DdhYVa92vfy+meQfgY8x\n6Nt/X5K/BrYwaOop/Qwn9+bTcUf+Gni1Wzy1exSwEXigW78NuGYiFUqaiGG7967q+vcdBLYD3wMO\nVdXhbpN9eCMPaaEMFf6uRfcGYD2DFt0XLbfZcu+1b780n05otr+qDgGPA5cCZyY5MmewHti/wnvs\n2y/NoWH69p8FvF5Vh5K8BXgfcDvwGHAtcB+wGXhwkoVqMTi5tziGme1fB2xLsorBkcKXq+rhJN8G\n7kvyKeBZBjf2kLQghunb/xyDm3Mevf5FVrhFl6T55xV+UqMMv9Qov9KrkTm5t9gc+aVGGX6pUYZf\napThlxrlhN+ULHovfyf3Tj6O/FKjDL/UKMMvNcrwS41ywk/LcoLv5OfILzXK8EuNGqdv/71J/j3J\nru7hcaK0QMbp2w/wJ1X1wDHeK2lODdPJp4Dl+vbrJOHkXptG6ttfVTu7H306yXNJ7khia15pgYzU\ntz/JrwK3AL8C/DqwFrh5uffat1+aT6P27b+qqg50t/J6DfhbVmjmad9+aT6N3Lc/ybqqOpAkDO7T\nt3vCtaoHnt/riHH69j/a/Y8hwC7gjyZYp6SejdO3f+NEKpI0FV7hJzXK8EuN8lt9JzEn93QsjvxS\nowy/1CjDLzXK8EuNcsJvhvrs5e/knk6UI7/UKMMvNcrwS40y/FKjnPBbQE7uqQ+O/FKjDL/UqKHD\n3zXxfDbJw93yBUl2Jtmb5P4kqydXpqS+ncjIfxOwZ8ny7cAdVXUh8GNgS5+FSZqsoSb8kqwH3g98\nGvhY17dvI/D73SbbgFuBOydQY/Oc4NMkDDvyfx74BPBmt/wO4FBVHe6W9wHn9lybpAka5l59HwAO\nVtXTS1cvs+myd/Gxb780n4Y57L8M+GCSTcAa4AwGRwJnJjmlG/3XA/uXe3NV3QXcBXBG1nqbL2lO\nHHfkr6pbqmp9VZ0PXAc8WlUfBh4Dru022ww8OLEqJfVunCv8bgbuS/Ip4Fng7n5KapuTe5qWEwp/\nVT3O4HZdVNWLrHCLLknzzyv8pEYZfqlRhl9qlOGXGmX4pUYZfqlRhl9qlOGXGmX4pUYZfqlRhl9q\nlOGXGmX4pUYZfqlRhl9qlOGXGmX4pUalano9NZP8F/AfwDuBH07tgydj0ffB+mdvEvvwi1V11jAb\nTjX8//ehyVNVdfHUP7hHi74P1j97s94HD/ulRhl+qVGzCv9dM/rcPi36Plj/7M10H2Zyzi9p9jzs\nlxo19fAnuSrJd5K8kGTrtD//RCW5J8nBJLuXrFubZHuSvd3z22dZ47EkOS/JY0n2JHk+yU3d+kXa\nhzVJnkjyrW4fPtmtvyDJzm4f7k+yeta1HkuSVUmeTfJwtzzT+qca/iSrgL8Cfhd4N3B9kndPs4YR\n3AtcddS6rcCOqroQ2NEtz6vDwMer6iLgUuCPu//mi7QPrwEbq+o9wAbgqiSXArcDd3T78GNgywxr\nHMZNwJ4lyzOtf9oj/yXAC1X1YlX9FLgPuHrKNZyQqvoG8KOjVl8NbOtebwOumWpRJ6CqDlTVM93r\nVxj84zuXxdqHqqpXu8VTu0cBG4EHuvVzvQ9J1gPvB/6mWw4zrn/a4T8X+P6S5X3dukVzTlUdgEG4\ngLNnXM9QkpwPvBfYyYLtQ3fIvAs4CGwHvgcc6m4RD/P/b+nzwCeAN7vldzDj+qcd/iyzzj83TEGS\ntwJfAT5aVT+ZdT0nqqreqKoNwHoGR5AXLbfZdKsaTpIPAAer6umlq5fZdKr1j3OL7lHsA85bsrwe\n2D/lGvrwcpJ1VXUgyToGo9HcSnIqg+B/saq+2q1eqH04oqoOJXmcwfzFmUlO6UbPef63dBnwwSSb\ngDXAGQyOBGZa/7RH/ieBC7tZztXAdcBDU66hDw8Bm7vXm4EHZ1jLMXXnlncDe6rqc0t+tEj7cFaS\nM7vXbwHex2Du4jHg2m6zud2HqrqlqtZX1fkM/s0/WlUfZtb1V9VUH8Am4LsMztn+bNqfP0K9XwIO\nAK8zOHLZwuB8bQewt3teO+s6j1H/bzI4nHwO2NU9Ni3YPvwa8Gy3D7uBP+/W/xLwBPAC8A/AabOu\ndYh9uRx4eB7q9wo/qVFe4Sc1yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9So/wWV/HXxBSiJXAAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdbc2048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "filename = 'PolygonImagesV7.pkl'\n",
    "dill.dump_session(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alternative pickle - Not in use.\n",
    "import pickle\n",
    "\n",
    "with open('PolygonImagesV3', 'wb') as f:\n",
    "    pickle.dump(train_x, f)\n",
    "    pickle.dump(val_x, f)\n",
    "    pickle.dump(test_x, f)\n",
    "    pickle.dump(train_y, f)\n",
    "    pickle.dump(val_y, f)\n",
    "    pickle.dump(test_y, f)\n",
    "    \n",
    "# for pickle above, you could use below to load.\n",
    "import pickle\n",
    "\n",
    "def load(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "            try:\n",
    "                yield pickle.load(f)\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "items = load(myfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Someone else's example didn't use it.\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import genfromtxt\n",
    "import gzip, cPickle\n",
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def dir_to_dataset(glob_files, loc_train_labels=\"\"):\n",
    "    print(\"Gonna process:\\n\\t %s\"%glob_files)\n",
    "    dataset = []\n",
    "    for file_count, file_name in enumerate( sorted(glob(glob_files),key=len) ):\n",
    "        print file_name\n",
    "        print 'Are we in the loop ?'\n",
    "        image = Image.open(file_name)\n",
    "        img = Image.open(file_name).convert('LA') #tograyscale\n",
    "        pixels = [f[0] for f in list(img.getdata())]\n",
    "        dataset.append(pixels)\n",
    "        if file_count % 10== 0:\n",
    "            print(\"\\t %s files processed\"%file_count)\n",
    "    # outfile = glob_files+\"out\"\n",
    "    # np.save(outfile, dataset)\n",
    "    if len(loc_train_labels) > 0:\n",
    "        df = pd.read_csv(loc_train_labels)\n",
    "        return np.array(dataset), np.array(df[\"Class\"])\n",
    "    else:\n",
    "        return np.array(dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dataa, y = dir_to_dataset(\"image\\\\*.bmp\",\"trainLabels.csv\") #change to *.bmp\n",
    "# Data and labels are read \n",
    "\n",
    "train_set_x = Dataa[:30]\n",
    "val_set_x = Dataa[31:40]\n",
    "test_set_x = Dataa[41:50]\n",
    "train_set_y = y[:30]\n",
    "val_set_y = y[31:40]\n",
    "test_set_y = y[41:50]\n",
    "# Divided dataset into 3 parts. I had 6281 images.\n",
    "\n",
    "train_set = train_set_x, train_set_y\n",
    "print 'Type of train_set_x',type(train_set_x)\n",
    "print train_set_x\n",
    "val_set = val_set_x, val_set_y\n",
    "test_set = test_set_x, val_set_y\n",
    "\n",
    "dataset = [train_set, val_set, test_set]\n",
    "\n",
    "f = gzip.open('traffic_file.pkl.gz','wb')\n",
    "pickle.dump(dataset, f, protocol=2)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}